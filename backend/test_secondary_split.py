from services.chunker import Chunker
from models import ChunkConfig, ChunkType

# 创建包含长内容的测试文档
test_content = '''# 测试文档：智能拆分与二次拆分

## 第一章 引言
这是测试文档的引言部分。

## 第二章 智能拆分原理
智能拆分是一种基于文档类型自动选择切分策略的技术。它能够识别不同类型的文档，如论文、法律文档、问答集等，并应用相应的切分策略。智能拆分的核心在于文档类型的准确识别和策略的合理选择。

### 2.1 文档类型识别
文档类型识别是智能拆分的第一步，它通过分析文档的结构、格式和内容特征来判断文档的类型。常见的文档类型包括：

1. 论文文档：通常包含摘要、引言、方法、结果、结论等部分，使用特定的标题格式。
2. 法律文档：包含条款、章节等结构，使用特定的编号系统。
3. 问答文档：包含问题和答案的配对结构。
4. 书籍文档：包含章节、前言、目录等结构。
5. 表格文档：包含大量表格数据。

文档类型识别的准确性直接影响后续切分策略的选择，因此需要综合考虑多种特征。

### 2.2 切分策略选择
根据识别出的文档类型，智能拆分系统会选择最适合的切分策略：

- 论文文档：基于章节标题进行切分，保留学术论文的结构完整性。
- 法律文档：基于条款和章节进行切分，确保法律条文的完整性。
- 问答文档：基于问答对进行切分，确保每个问答对的完整性。
- 书籍文档：基于章节进行切分，保留书籍的叙事结构。
- 表格文档：基于表格进行切分，确保表格数据的完整性。

### 2.3 切分参数优化
切分参数的优化是智能拆分的重要组成部分，它直接影响切分结果的质量。常见的切分参数包括：

1. 切分大小：控制每个切分单元的大小，通常以token数量或字符数量为单位。
2. 重叠比例：控制相邻切分单元之间的重叠程度，以确保上下文的连续性。
3. 分隔符选择：选择合适的分隔符，以确保切分点的合理性。

参数的选择需要根据文档类型、内容特征和后续处理的需求来确定。

## 第三章 二次拆分技术
二次拆分是针对智能拆分后可能出现的超长片段进行的精细化处理。它基于子标题层级结构，将超长片段进一步拆分为更小的、符合字符数量要求的单元。

### 3.1 二次拆分的必要性
在智能拆分后，可能会出现一些超长的片段，这些片段的字符数量超过了合理的阈值。超长片段会带来以下问题：

1. 处理效率下降：超长片段会增加后续处理的时间和资源消耗。
2. 信息提取困难：超长片段不利于信息的精准提取和理解。
3. 上下文管理复杂：超长片段的上下文管理更加复杂，容易导致信息丢失或混淆。

因此，二次拆分是确保切分质量的重要步骤。

### 3.2 二次拆分的实现原理
二次拆分的实现原理包括以下几个步骤：

1. 子标题检测：识别文档中的子标题层级结构，如二级标题、三级标题等。
2. 基于子标题的初步切分：以子标题为边界，将超长片段初步拆分为多个单元。
3. 字符数量控制：检查每个初步切分单元的字符数量，如果仍然超过阈值，则进一步基于段落进行切分。
4. 内容完整性保证：确保每个拆分单元都包含完整的标题和内容，避免内容的割裂。
5. 结构维持：保持原始内容的逻辑结构和段落顺序，确保信息的连贯性。

### 3.3 二次拆分的质量控制
二次拆分的质量控制包括以下几个方面：

1. 字符数量控制：确保每个拆分单元的字符数量不超过预设的阈值，推荐单个单元字符数不超过1500。
2. 内容完整性：确保所有原始内容都被准确分配至相应的拆分单元，无遗漏或重复。
3. 结构完整性：保持原始内容的逻辑结构和层级关系，不得擅自调整内容顺序或层级。
4. 上下文连续性：确保拆分单元之间的上下文连续性，避免信息断裂。
5. 验证标准：拆分完成后进行完整性校验，确认所有原始内容均被准确分配。

## 第四章 实验与结果
为了验证智能拆分和二次拆分的效果，我们进行了一系列实验。

### 4.1 实验数据集
我们使用了多种类型的文档作为实验数据：

1. 学术论文：包含不同领域的学术论文，如计算机科学、医学、经济学等。
2. 法律文档：包含法律法规、合同等法律文件。
3. 问答文档：包含FAQ、考试题库等问答集。
4. 书籍文档：包含不同类型的书籍，如小说、教材等。
5. 表格文档：包含大量表格数据的文档，如财务报表、统计数据等。

### 4.2 实验指标
我们使用以下指标来评估切分效果：

1. 切分质量：评估切分单元的内容完整性、结构完整性和上下文连续性。
2. 处理效率：评估切分过程的时间消耗和资源占用。
3. 字符数量控制：评估拆分单元的字符数量是否在合理范围内。
4. 召回率：评估所有原始内容是否都被准确分配至相应的拆分单元。
5. 精确率：评估拆分单元是否包含完整的、有意义的信息。

### 4.3 实验结果
实验结果表明，智能拆分和二次拆分的结合使用能够显著提高切分质量：

1. 文档类型识别准确率达到90%以上，能够准确识别常见类型的文档。
2. 切分质量得到显著提升，拆分单元的内容完整性和结构完整性得到保证。
3. 字符数量控制效果良好，95%以上的拆分单元字符数量在1500以内。
4. 处理效率满足实际应用需求，能够在合理的时间内完成切分任务。
5. 召回率和精确率均达到95%以上，确保所有原始内容都被准确分配。

## 第五章 结论与展望
智能拆分和二次拆分技术的结合使用为文档切分提供了一种高效、准确的解决方案。

### 5.1 主要结论
1. 智能拆分能够根据文档类型自动选择切分策略，提高切分的准确性和适应性。
2. 二次拆分能够有效控制拆分单元的字符数量，确保切分质量。
3. 两者的结合使用能够显著提高文档切分的整体效果，满足不同场景的需求。

### 5.2 未来展望
1. 进一步提高文档类型识别的准确率，支持更多类型的文档。
2. 优化切分策略，提高切分的质量和效率。
3. 研究语义感知的切分技术，进一步提高切分的智能化水平。
4. 开发用户友好的配置界面，允许用户根据具体需求调整切分参数。
5. 扩展应用场景，将智能切分技术应用到更多领域。

通过不断的研究和改进，智能切分技术将在文档处理、信息提取、知识管理等领域发挥越来越重要的作用。
'''

# 创建切分器实例
chunker = Chunker()

# 创建智能切分配置
config = ChunkConfig(type=ChunkType.INTELLIGENT)

# 执行切分
print("开始智能切分...")
chunks = chunker.chunk(test_content, 'test_long_doc', config)

# 输出结果
print(f"\n智能切分完成，生成了 {len(chunks)} 个片段")
print("\n片段详情：")
for i, chunk in enumerate(chunks):
    print(f"\n片段 {i+1}:")
    print(f"字符数: {len(chunk.content)}")
    print(f"内容前100字符: {chunk.content[:100]}...")
    
# 验证字符数量控制
print("\n\n字符数量控制验证：")
over_2000 = [i for i, c in enumerate(chunks) if len(c.content) > 2000]
over_1500 = [i for i, c in enumerate(chunks) if len(c.content) > 1500]

print(f"超过2000字符的片段数量: {len(over_2000)}")
print(f"超过1500字符的片段数量: {len(over_1500)}")
print(f"所有片段字符数均在合理范围内: {len(over_2000) == 0}")

# 验证内容完整性
total_characters = sum(len(c.content) for c in chunks)
original_characters = len(test_content.strip())
print(f"\n\n内容完整性验证：")
print(f"原始内容字符数: {original_characters}")
print(f"拆分后总字符数: {total_characters}")
print(f"内容完整性: {'完整' if abs(original_characters - total_characters) < 100 else '可能存在丢失'}")
