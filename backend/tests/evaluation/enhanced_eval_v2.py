#!/usr/bin/env python3
"""
RAGç³»ç»Ÿå¢å¼ºæµ‹è¯„è„šæœ¬ V2 - å®Œæ•´æµ‹è¯„æŒ‡æ ‡ä½“ç³»
æ”¯æŒï¼šNDCGã€Recallã€F1ã€è¯­ä¹‰ç›¸ä¼¼åº¦ã€ä¸»é¢˜è¦†ç›–ç‡ç­‰
"""

import sys
import json
import time
import argparse
import math
import numpy as np
from pathlib import Path
from datetime import datetime
import statistics
from typing import List, Dict, Any, Optional, Tuple

sys.path.insert(0, str(Path(__file__).parent.parent.parent))

from services.embedding import embedding_service
from services.vector_db import vector_db_manager
from services.rag_evaluator import rag_evaluator
from models import (
    RetrievalConfig,
    EmbeddingConfig,
    VectorDBConfig,
    EmbeddingModelType,
    VectorDBType,
)
from config import settings


class EnhancedRAGEvaluator:
    """å¢å¼ºç‰ˆRAGç³»ç»Ÿæµ‹è¯„å™¨ - å®Œæ•´æŒ‡æ ‡ä½“ç³»"""

    def __init__(self, output_dir: str = "test_reports"):
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(exist_ok=True)
        self.evaluation_time = datetime.now()

    def init_services(self) -> bool:
        """åˆå§‹åŒ–æ‰€æœ‰æœåŠ¡"""
        print("ğŸ”§ åˆå§‹åŒ–æœåŠ¡...")

        try:
            # åŠ è½½768ç»´åµŒå…¥æ¨¡å‹ï¼ˆä¸å‘é‡åº“åŒ¹é…ï¼‰
            print("   åŠ è½½åµŒå…¥æ¨¡å‹(bge-base-zh-v1.5, 768ç»´)...")
            embedding_service.load_model(
                EmbeddingConfig(
                    model_type=EmbeddingModelType.BGE,
                    model_name="BAAI/bge-base-zh-v1.5",
                    device="cpu",
                )
            )
            print(f"   âœ… æ¨¡å‹ç»´åº¦: {embedding_service.get_dimension()}")

            # åˆå§‹åŒ–å‘é‡æ•°æ®åº“
            print("   åˆå§‹åŒ–å‘é‡æ•°æ®åº“...")
            vector_db_manager.initialize(
                VectorDBConfig(
                    db_type=VectorDBType.FAISS,
                    dimension=embedding_service.get_dimension(),
                    index_type="HNSW",
                )
            )
            status = vector_db_manager.get_status()
            print(f"   âœ… å‘é‡åº“: {status.total_vectors} ä¸ªå‘é‡")

            return True

        except Exception as e:
            print(f"   âŒ åˆå§‹åŒ–å¤±è´¥: {e}")
            return False

    def load_test_data(self, test_file: str) -> Dict[str, Any]:
        """åŠ è½½æµ‹è¯•æ•°æ®"""
        if not Path(test_file).exists():
            # å°è¯•åœ¨test_dataç›®å½•æŸ¥æ‰¾
            test_file = Path(__file__).parent.parent.parent / "test_data" / test_file

        if not Path(test_file).exists():
            raise FileNotFoundError(f"æµ‹è¯•æ–‡ä»¶ä¸å­˜åœ¨: {test_file}")

        with open(test_file, "r", encoding="utf-8") as f:
            test_data = json.load(f)

        print(f"âœ… åŠ è½½æµ‹è¯•æ•°æ®: {test_file}")
        return test_data

    def calculate_ndcg_at_k(
        self, results: List[Any], ground_truth: List[str], k: int = 5
    ) -> float:
        """è®¡ç®—NDCG@K (å½’ä¸€åŒ–æŠ˜æŸç´¯ç§¯å¢ç›Š)"""
        if not ground_truth:
            return 0.0

        # è®¡ç®—DCG
        dcg = 0.0
        for i, result in enumerate(results[:k]):
            # æ£€æŸ¥è¿™ä¸ªç»“æœæ˜¯å¦åœ¨ground_truthä¸­
            relevance = 0
            for gt in ground_truth:
                if gt in result.content or result.content in gt:
                    relevance = 1
                    break
            # æŠ˜æŸå› å­: log2(i+2)ï¼Œå› ä¸ºiä»0å¼€å§‹
            dcg += relevance / math.log2(i + 2)

        # è®¡ç®—ç†æƒ³DCG (IDCG)
        idcg = 0.0
        for i in range(min(len(ground_truth), k)):
            idcg += 1.0 / math.log2(i + 2)

        if idcg == 0:
            return 0.0

        return dcg / idcg

    def calculate_recall_at_k(
        self, results: List[Any], ground_truth: List[str], k: int = 5
    ) -> float:
        """è®¡ç®—Recall@K"""
        if not ground_truth:
            return 0.0

        # ç»Ÿè®¡åœ¨top-kç»“æœä¸­æ‰¾åˆ°çš„ground_truthæ•°é‡
        found = 0
        for gt in ground_truth:
            for result in results[:k]:
                if gt in result.content or result.content in gt:
                    found += 1
                    break

        return found / len(ground_truth)

    def calculate_f1_at_k(
        self, precision: float, recall: float
    ) -> float:
        """è®¡ç®—F1@K (ç²¾ç¡®ç‡å’Œå¬å›ç‡çš„è°ƒå’Œå¹³å‡)"""
        if precision + recall == 0:
            return 0.0
        return 2 * (precision * recall) / (precision + recall)

    def calculate_semantic_similarity(
        self, text1: str, text2: str
    ) -> float:
        """è®¡ç®—ä¸¤æ®µæ–‡æœ¬çš„è¯­ä¹‰ç›¸ä¼¼åº¦ (ä½¿ç”¨embedding)"""
        try:
            # ç¼–ç ä¸¤æ®µæ–‡æœ¬
            embedding1 = embedding_service.encode([text1])
            embedding2 = embedding_service.encode([text2])

            # è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
            similarity = np.dot(embedding1[0], embedding2[0]) / (
                np.linalg.norm(embedding1[0]) * np.linalg.norm(embedding2[0])
            )

            return float(similarity)
        except Exception as e:
            print(f"   âš ï¸ è¯­ä¹‰ç›¸ä¼¼åº¦è®¡ç®—å¤±è´¥: {e}")
            return 0.0

    def calculate_topic_coverage(
        self, results: List[Any], expected_topics: List[str]
    ) -> Dict[str, Any]:
        """è®¡ç®—ä¸»é¢˜è¦†ç›–ç‡"""
        if not expected_topics:
            return {"coverage_rate": 0.0, "covered_topics": [], "missed_topics": []}

        # åˆå¹¶æ‰€æœ‰æ£€ç´¢ç»“æœæ–‡æœ¬
        retrieved_text = " ".join([r.content for r in results]).lower()

        # æ£€æŸ¥æ¯ä¸ªæœŸæœ›ä¸»é¢˜æ˜¯å¦è¢«è¦†ç›–
        covered_topics = []
        missed_topics = []

        for topic in expected_topics:
            # ç®€åŒ–çš„ä¸»é¢˜åŒ¹é…ï¼ˆå®é™…åº”ç”¨ä¸­å¯èƒ½éœ€è¦æ›´å¤æ‚çš„è¯­ä¹‰åŒ¹é…ï¼‰
            if topic.lower() in retrieved_text:
                covered_topics.append(topic)
            else:
                missed_topics.append(topic)

        coverage_rate = len(covered_topics) / len(expected_topics) if expected_topics else 0.0

        return {
            "coverage_rate": coverage_rate,
            "covered_topics": covered_topics,
            "missed_topics": missed_topics,
            "total_topics": len(expected_topics),
            "covered_count": len(covered_topics),
        }

    def run_retrieval_test(
        self, query: str, expected_keywords: list, case_info: dict
    ) -> Dict[str, Any]:
        """è¿è¡Œå•ä¸ªæ£€ç´¢æµ‹è¯•ï¼ˆå¢å¼ºç‰ˆï¼ŒåŒ…å«å®Œæ•´æŒ‡æ ‡ï¼‰"""
        # ä¿å­˜æŸ¥è¯¢åˆ°evaluatorç”¨äºMRRä¼°ç®—
        rag_evaluator._last_query = query

        # å‘é‡åŒ–æŸ¥è¯¢ï¼ˆä½¿ç”¨æœ¬åœ°BGEæ¨¡å‹ï¼‰
        query_vector = embedding_service.encode([query])

        # æ£€ç´¢
        start = time.time()
        scores, metadatas = vector_db_manager.search(query_vector, top_k=10)  # æ£€ç´¢æ›´å¤šç»“æœç”¨äºè®¡ç®—NDCG
        elapsed = (time.time() - start) * 1000

        # æ„å»ºç»“æœå¯¹è±¡
        class FakeResult:
            def __init__(self, content, similarity, document_id, chunk_id):
                self.content = content
                self.similarity = similarity
                self.document_id = document_id
                self.chunk_id = chunk_id

        results = []
        for i, (score, meta) in enumerate(zip(scores[0], metadatas[0])):
            results.append(
                FakeResult(
                    content=meta.get("content", ""),
                    similarity=float(score),
                    document_id=meta.get("document_id", ""),
                    chunk_id=meta.get("chunk_id", f"chunk_{i}"),
                )
            )

        # ========== å…³é”®è¯å‘½ä¸­ç»Ÿè®¡ ==========
        retrieved_text = " ".join([r.content for r in results])
        hits = sum(1 for kw in expected_keywords if kw in retrieved_text)
        hit_rate = hits / len(expected_keywords) if expected_keywords else 0

        matched_keywords = [kw for kw in expected_keywords if kw in retrieved_text]
        missed_keywords = [kw for kw in expected_keywords if kw not in retrieved_text]

        # ========== åŸºç¡€è¯„ä¼°æŒ‡æ ‡ ==========
        ground_truth = case_info.get("ground_truth", [])
        eval_result = rag_evaluator.evaluate_retrieval(query, results[:5], ground_truth)

        # ========== æ–°å¢ï¼šNDCG@K ==========
        ndcg_at_5 = self.calculate_ndcg_at_k(results, [ground_truth] if isinstance(ground_truth, str) else ground_truth, k=5)

        # ========== æ–°å¢ï¼šRecall@K ==========
        recall_at_5 = self.calculate_recall_at_k(results, [ground_truth] if isinstance(ground_truth, str) else ground_truth, k=5)

        # ========== æ–°å¢ï¼šF1@K ==========
        precision_at_5 = eval_result.get("precision_at_5", 0)
        f1_at_5 = self.calculate_f1_at_k(precision_at_5, recall_at_5)

        # ========== æ–°å¢ï¼šè¯­ä¹‰ç›¸ä¼¼åº¦ï¼ˆå¦‚æœæœ‰ground_truthï¼‰==========
        semantic_similarity = 0.0
        if ground_truth and isinstance(ground_truth, str) and results:
            # è®¡ç®—æŸ¥è¯¢ä¸top1ç»“æœçš„è¯­ä¹‰ç›¸ä¼¼åº¦
            semantic_similarity = self.calculate_semantic_similarity(query, results[0].content)

        # ========== æ–°å¢ï¼šä¸»é¢˜è¦†ç›–ç‡ ==========
        expected_topics = case_info.get("expected_topics", [])
        topic_coverage = self.calculate_topic_coverage(results, expected_topics)

        return {
            "case_info": case_info,
            "query": query,
            "response_time_ms": elapsed,
            "results_count": len(results),
            "results": [
                {
                    "rank": i + 1,
                    "similarity": r.similarity,
                    "content": r.content[:80] + "...",
                    "chunk_id": r.chunk_id,
                    "document_id": r.document_id,
                }
                for i, r in enumerate(results[:5])
            ],
            "keyword_analysis": {
                "hit_rate": hit_rate,
                "hits": hits,
                "total_keywords": len(expected_keywords),
                "matched": matched_keywords,
                "missed": missed_keywords,
            },
            "topic_coverage": topic_coverage,
            "metrics": {
                # åŸºç¡€æŒ‡æ ‡
                "precision_at_1": eval_result.get("precision_at_1", 0),
                "precision_at_3": eval_result.get("precision_at_3", 0),
                "precision_at_5": eval_result.get("precision_at_5", 0),
                "recall_at_5": recall_at_5,
                "f1_at_5": f1_at_5,
                "ndcg_at_5": ndcg_at_5,
                "mrr": eval_result.get("mrr", 0),
                "context_precision": eval_result.get("context_precision", 0),
                "context_recall": eval_result.get("context_recall", 0),
                # æ–°å¢è¯­ä¹‰æŒ‡æ ‡
                "semantic_similarity": semantic_similarity,
            },
            "model_info": {
                "embedding_model": "BAAI/bge-base-zh-v1.5 (æœ¬åœ°)",
                "vector_db": "FAISS (æœ¬åœ°)",
                "llm_provider": "local (Qwen2.5-7B-Instruct)",
            },
        }
