#!/usr/bin/env python3
"""
RAGç³»ç»Ÿæ‰¹é‡æµ‹è¯•è„šæœ¬ - ä½¿ç”¨æ‰©å±•æµ‹è¯•æ•°æ®é›†(125æ¡)

ä½¿ç”¨æ–¹æ³•:
  python3 batch_test.py --mode retrieval       # è¿è¡Œæ£€ç´¢æµ‹è¯•
  python3 batch_test.py --mode e2e            # è¿è¡Œç«¯åˆ°ç«¯æµ‹è¯•
  python3 batch_test.py --mode all            # è¿è¡Œæ‰€æœ‰æµ‹è¯•
  python3 batch_test.py --category ä½å®¿æ ‡å‡†    # æŒ‰åˆ†ç±»æµ‹è¯•
  python3 batch_test.py --difficulty easy     # æŒ‰éš¾åº¦æµ‹è¯•
  python3 batch_test.py --limit 10            # åªæµ‹å‰10æ¡
"""

import argparse
import json
import sys
import time
from pathlib import Path
from datetime import datetime
from typing import List, Dict, Any

sys.path.insert(0, str(Path(__file__).parent.parent.parent))

from services.rag_generator import rag_generator
from services.embedding import embedding_service
from services.vector_db import vector_db_manager
from models import RetrievalConfig, GenerationConfig, EmbeddingConfig, VectorDBConfig
from models import EmbeddingModelType, VectorDBType
from config import settings


class BatchTester:
    """æ‰¹é‡æµ‹è¯•å™¨"""

    def __init__(self):
        self.test_data = None
        self.results = []
        self.load_test_data()
        self.init_services()

    def load_test_data(self):
        """åŠ è½½æµ‹è¯•æ•°æ®"""
        test_file = Path(__file__).parent / "test_data" / "test_dataset_extended.json"
        with open(test_file, "r", encoding="utf-8") as f:
            self.test_data = json.load(f)
        print(f"âœ… åŠ è½½æµ‹è¯•æ•°æ®: {test_file}")

    def init_services(self):
        """åˆå§‹åŒ–æœåŠ¡"""
        print("ğŸ“¦ åˆå§‹åŒ–æœåŠ¡...")

        if not embedding_service.is_loaded():
            config = EmbeddingConfig(
                model_type=EmbeddingModelType.BGE,
                model_name="BAAI/bge-small-zh-v1.5",
                device="cpu",
            )
            embedding_service.load_model(config)

        dimension = embedding_service.get_dimension()
        vdb_config = VectorDBConfig(
            db_type=VectorDBType.FAISS, dimension=dimension, index_type="HNSW"
        )
        vector_db_manager.initialize(vdb_config)

        status = vector_db_manager.get_status()
        print(f"   âœ… å‘é‡åº“: {status.total_vectors} ä¸ªå‘é‡\n")

    def test_retrieval(self, test_cases: List[Dict], limit: int = None) -> Dict:
        """æµ‹è¯•æ£€ç´¢åŠŸèƒ½"""
        if limit:
            test_cases = test_cases[:limit]

        print(f"\nğŸ” è¿è¡Œæ£€ç´¢æµ‹è¯• ({len(test_cases)} æ¡)...")
        print("=" * 80)

        results = []
        passed = 0

        for i, case in enumerate(test_cases, 1):
            print(f"\n[{i}/{len(test_cases)}] {case['id']}")
            print(f"æŸ¥è¯¢: {case['query']}")
            print(f"åˆ†ç±»: {case['category']} | éš¾åº¦: {case['difficulty']}")

            # æ‰§è¡Œæ£€ç´¢
            start = time.time()
            try:
                from services.retriever import retriever

                retrieval_config = RetrievalConfig(top_k=5)
                response = retriever.retrieve(case["query"], retrieval_config)
                elapsed = (time.time() - start) * 1000

                # æ£€æŸ¥å…³é”®è¯å‘½ä¸­
                retrieved_text = " ".join([r.content for r in response.results])
                keywords_hit = sum(
                    1 for kw in case["expected_keywords"] if kw in retrieved_text
                )
                keyword_rate = (
                    keywords_hit / len(case["expected_keywords"])
                    if case["expected_keywords"]
                    else 1.0
                )

                # è¯„ä¼°ç»“æœ
                if keyword_rate >= 0.6:
                    status = "âœ… é€šè¿‡"
                    passed += 1
                else:
                    status = "âš ï¸  è­¦å‘Š"

                print(f"   æ£€ç´¢ç»“æœ: {len(response.results)} ä¸ªç‰‡æ®µ")
                print(
                    f"   å…³é”®è¯å‘½ä¸­: {keywords_hit}/{len(case['expected_keywords'])} ({keyword_rate * 100:.0f}%)"
                )
                print(f"   å“åº”æ—¶é—´: {elapsed:.1f}ms")
                print(f"   çŠ¶æ€: {status}")

                results.append(
                    {
                        "id": case["id"],
                        "query": case["query"],
                        "status": "passed" if keyword_rate >= 0.6 else "warning",
                        "keyword_rate": keyword_rate,
                        "response_time_ms": elapsed,
                        "retrieved_count": len(response.results),
                    }
                )

            except Exception as e:
                print(f"   âŒ é”™è¯¯: {str(e)}")
                results.append(
                    {
                        "id": case["id"],
                        "query": case["query"],
                        "status": "error",
                        "error": str(e),
                    }
                )

        # ç»Ÿè®¡
        print("\n" + "=" * 80)
        print(
            f"ğŸ“Š æ£€ç´¢æµ‹è¯•å®Œæˆ: {passed}/{len(test_cases)} é€šè¿‡ ({passed / len(test_cases) * 100:.1f}%)"
        )

        return {
            "total": len(test_cases),
            "passed": passed,
            "failed": len(test_cases) - passed,
            "pass_rate": passed / len(test_cases) if test_cases else 0,
            "results": results,
        }

    def test_end_to_end(self, test_cases: List[Dict], limit: int = None) -> Dict:
        """æµ‹è¯•ç«¯åˆ°ç«¯åŠŸèƒ½"""
        if limit:
            test_cases = test_cases[:limit]

        print(f"\nğŸ¯ è¿è¡Œç«¯åˆ°ç«¯æµ‹è¯• ({len(test_cases)} æ¡)...")
        print("=" * 80)

        results = []
        passed = 0

        for i, case in enumerate(test_cases, 1):
            print(f"\n[{i}/{len(test_cases)}] {case['id']}")
            print(f"æŸ¥è¯¢: {case['query'][:60]}...")

            # æ‰§è¡ŒRAG
            start = time.time()
            try:
                response = rag_generator.generate(
                    query=case["query"],
                    retrieval_config=RetrievalConfig(top_k=3),
                    generation_config=GenerationConfig(
                        llm_provider=settings.llm_provider,
                        llm_model=settings.llm_model,
                        temperature=0.7,
                        max_tokens=500,
                    ),
                )
                elapsed = (time.time() - start) * 1000

                answer = response.answer

                # æ£€æŸ¥å¿…å«å…³é”®è¯
                contains_hit = sum(
                    1 for kw in case["expected_answer_contains"] if kw in answer
                )
                contains_rate = (
                    contains_hit / len(case["expected_answer_contains"])
                    if case["expected_answer_contains"]
                    else 1.0
                )

                # æ£€æŸ¥ä¸åº”å«æœ‰çš„å…³é”®è¯
                not_contains_hit = sum(
                    1 for kw in case["expected_answer_not_contains"] if kw in answer
                )

                # æ£€æŸ¥å“åº”æ—¶é—´
                time_ok = elapsed <= case["max_response_time_ms"]

                # æ£€æŸ¥é•¿åº¦
                length_ok = len(answer) >= case["min_answer_length"]

                # ç»¼åˆè¯„ä¼°
                if contains_rate >= 0.7 and not_contains_hit == 0 and length_ok:
                    status = "âœ… é€šè¿‡"
                    passed += 1
                elif contains_rate >= 0.5:
                    status = "âš ï¸  éƒ¨åˆ†é€šè¿‡"
                else:
                    status = "âŒ æœªé€šè¿‡"

                print(f"   å›ç­”é•¿åº¦: {len(answer)} å­—ç¬¦")
                print(
                    f"   å¿…å«å…³é”®è¯: {contains_hit}/{len(case['expected_answer_contains'])}"
                )
                print(f"   åº”æ’é™¤å…³é”®è¯è¿è§„: {not_contains_hit}")
                print(f"   å“åº”æ—¶é—´: {elapsed / 1000:.1f}s")
                print(f"   çŠ¶æ€: {status}")

                results.append(
                    {
                        "id": case["id"],
                        "query": case["query"],
                        "status": "passed"
                        if status == "âœ… é€šè¿‡"
                        else "partial"
                        if status == "âš ï¸  éƒ¨åˆ†é€šè¿‡"
                        else "failed",
                        "contains_rate": contains_rate,
                        "response_time_ms": elapsed,
                        "answer_length": len(answer),
                    }
                )

            except Exception as e:
                print(f"   âŒ é”™è¯¯: {str(e)}")
                results.append(
                    {
                        "id": case["id"],
                        "query": case["query"],
                        "status": "error",
                        "error": str(e),
                    }
                )

        # ç»Ÿè®¡
        print("\n" + "=" * 80)
        print(
            f"ğŸ“Š ç«¯åˆ°ç«¯æµ‹è¯•å®Œæˆ: {passed}/{len(test_cases)} é€šè¿‡ ({passed / len(test_cases) * 100:.1f}%)"
        )

        return {
            "total": len(test_cases),
            "passed": passed,
            "failed": len(test_cases) - passed,
            "pass_rate": passed / len(test_cases) if test_cases else 0,
            "results": results,
        }

    def run_all_tests(self, limit: int = None):
        """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
        print("\n" + "=" * 80)
        print("ğŸš€ RAGç³»ç»Ÿæ‰¹é‡æµ‹è¯• - æ‰©å±•æ•°æ®é›† (125æ¡)")
        print("=" * 80)

        # åˆå¹¶æ£€ç´¢æµ‹è¯•
        retrieval_cases = self.test_data["retrieval_test_cases"] + self.test_data.get(
            "retrieval_test_cases_part2", []
        )
        e2e_cases = self.test_data["end_to_end_test_cases"]

        # è¿è¡Œæµ‹è¯•
        retrieval_results = self.test_retrieval(retrieval_cases, limit)
        e2e_results = self.test_end_to_end(e2e_cases, limit)

        # ç”ŸæˆæŠ¥å‘Š
        self.generate_report(retrieval_results, e2e_results)

    def filter_by_category(self, category: str) -> List[Dict]:
        """æŒ‰åˆ†ç±»ç­›é€‰"""
        retrieval_cases = self.test_data["retrieval_test_cases"] + self.test_data.get(
            "retrieval_test_cases_part2", []
        )
        return [c for c in retrieval_cases if c["category"] == category]

    def filter_by_difficulty(self, difficulty: str) -> List[Dict]:
        """æŒ‰éš¾åº¦ç­›é€‰"""
        retrieval_cases = self.test_data["retrieval_test_cases"] + self.test_data.get(
            "retrieval_test_cases_part2", []
        )
        return [c for c in retrieval_cases if c["difficulty"] == difficulty]

    def generate_report(self, retrieval_results: Dict, e2e_results: Dict):
        """ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        report_file = (
            Path(__file__).parent / f"test_reports/batch_test_report_{timestamp}.json"
        )
        report_file.parent.mkdir(exist_ok=True)

        report = {
            "timestamp": timestamp,
            "summary": {
                "retrieval": {
                    "total": retrieval_results["total"],
                    "passed": retrieval_results["passed"],
                    "pass_rate": retrieval_results["pass_rate"],
                },
                "end_to_end": {
                    "total": e2e_results["total"],
                    "passed": e2e_results["passed"],
                    "pass_rate": e2e_results["pass_rate"],
                },
                "overall_pass_rate": (
                    retrieval_results["passed"] + e2e_results["passed"]
                )
                / (retrieval_results["total"] + e2e_results["total"]),
            },
            "retrieval_results": retrieval_results,
            "e2e_results": e2e_results,
        }

        with open(report_file, "w", encoding="utf-8") as f:
            json.dump(report, f, ensure_ascii=False, indent=2)

        print(f"\nğŸ“ æµ‹è¯•æŠ¥å‘Šå·²ä¿å­˜: {report_file}")
        print("\n" + "=" * 80)
        print("ğŸ“Š æ€»ä½“æµ‹è¯•ç»“æœ")
        print("=" * 80)
        print(
            f"æ£€ç´¢æµ‹è¯•: {retrieval_results['passed']}/{retrieval_results['total']} é€šè¿‡ ({retrieval_results['pass_rate'] * 100:.1f}%)"
        )
        print(
            f"ç«¯åˆ°ç«¯æµ‹è¯•: {e2e_results['passed']}/{e2e_results['total']} é€šè¿‡ ({e2e_results['pass_rate'] * 100:.1f}%)"
        )
        print(f"æ€»ä½“é€šè¿‡ç‡: {report['summary']['overall_pass_rate'] * 100:.1f}%")


def main():
    parser = argparse.ArgumentParser(description="RAGç³»ç»Ÿæ‰¹é‡æµ‹è¯•")
    parser.add_argument(
        "--mode", choices=["retrieval", "e2e", "all"], default="all", help="æµ‹è¯•æ¨¡å¼"
    )
    parser.add_argument("--category", type=str, help="æŒ‰åˆ†ç±»ç­›é€‰(å¦‚: ä½å®¿æ ‡å‡†)")
    parser.add_argument(
        "--difficulty", choices=["easy", "medium", "hard"], help="æŒ‰éš¾åº¦ç­›é€‰"
    )
    parser.add_argument("--limit", type=int, help="é™åˆ¶æµ‹è¯•æ•°é‡")
    parser.add_argument("--list-categories", action="store_true", help="åˆ—å‡ºæ‰€æœ‰åˆ†ç±»")

    args = parser.parse_args()

    tester = BatchTester()

    if args.list_categories:
        print("\nğŸ“‹ å¯ç”¨åˆ†ç±»:")
        categories = set()
        for case in tester.test_data["retrieval_test_cases"]:
            categories.add(case["category"])
        for cat in sorted(categories):
            count = len(tester.filter_by_category(cat))
            print(f"  â€¢ {cat}: {count} æ¡")
        return

    if args.category:
        cases = tester.filter_by_category(args.category)
        print(f"\nç­›é€‰åˆ†ç±» '{args.category}': {len(cases)} æ¡æµ‹è¯•")
        tester.test_retrieval(cases, args.limit)
    elif args.difficulty:
        cases = tester.filter_by_difficulty(args.difficulty)
        print(f"\nç­›é€‰éš¾åº¦ '{args.difficulty}': {len(cases)} æ¡æµ‹è¯•")
        tester.test_retrieval(cases, args.limit)
    elif args.mode == "retrieval":
        cases = tester.test_data["retrieval_test_cases"] + tester.test_data.get(
            "retrieval_test_cases_part2", []
        )
        tester.test_retrieval(cases, args.limit)
    elif args.mode == "e2e":
        tester.test_end_to_end(tester.test_data["end_to_end_test_cases"], args.limit)
    else:
        tester.run_all_tests(args.limit)


if __name__ == "__main__":
    main()
