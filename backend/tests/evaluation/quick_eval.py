#!/usr/bin/env python3
"""
å¿«é€Ÿæœ¬åœ°æ¨¡å‹æµ‹è¯„è„šæœ¬
"""
import sys
import time
from pathlib import Path
from datetime import datetime

sys.path.insert(0, str(Path(__file__).parent.parent.parent))

from services.embedding import embedding_service
from services.vector_db import vector_db_manager
from services.rag_generator import rag_generator
from services.rag_evaluator import rag_evaluator
from models import RetrievalConfig, GenerationConfig, EmbeddingConfig, VectorDBConfig, EmbeddingModelType, VectorDBType
from config import settings


def quick_local_eval(limit: int = 5):
    """å¿«é€Ÿæœ¬åœ°æ¨¡å‹æµ‹è¯„"""
    print("\nğŸš€ RAGç³»ç»Ÿå¿«é€Ÿæµ‹è¯„ï¼ˆæœ¬åœ°æ¨¡å‹ï¼‰")
    print("="*60)
    print(f"æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("ğŸ“ ä½¿ç”¨é…ç½®:")
    print(f"   LLM: {settings.llm_provider} - {settings.llm_model}")
    print(f"   åµŒå…¥: {settings.embedding_model_name}")
    print(f"   å‘é‡åº“: {settings.vector_db_type}")
    
    try:
        # åº”ç”¨MRRä¿®å¤
        import tests.evaluation.mrr_debug as mrr_debug
        mrr_debug.patch_rag_evaluator()
        print("âœ… MRRä¿®å¤å·²åº”ç”¨")
    except:
        print("âš ï¸ MRRä¿®å¤å¤±è´¥ï¼Œç»§ç»­æµ‹è¯•...")
    
    # åˆå§‹åŒ–æœåŠ¡
    print("ğŸ”§ åˆå§‹åŒ–æœåŠ¡...")
    embedding_service.load_model(EmbeddingConfig(
        model_type=EmbeddingModelType.BGE,
        model_name=settings.embedding_model_name,
        device=settings.embedding_device,
    ))
    vector_db_manager.initialize(VectorDBConfig(
        db_type=VectorDBType.FAISS,
        dimension=embedding_service.get_dimension(),
        index_type=settings.faiss_index_type,
    ))
    
    print(f"âœ… åˆå§‹åŒ–å®Œæˆ")
    
    # å¿«é€Ÿæµ‹è¯•ç”¨ä¾‹
    test_queries = [
        {
            "query": "å·®æ—…è´¹æ ‡å‡†æ˜¯ä»€ä¹ˆï¼Ÿ",
            "expected_keywords": ["å·®æ—…è´¹", "æ ‡å‡†", "è´¹ç”¨"],
            "ground_truth_chunks": ["2"],  # å‡è®¾
        },
        {
            "query": "8-9çº§å‘˜å·¥ä½å®¿æŠ¥é”€æ ‡å‡†",
            "expected_keywords": ["ä½å®¿", "8-9çº§", "å‘˜å·¥", "æ ‡å‡†"],
        },
        {
            "query": "æŠ¥é”€éœ€è¦ä»€ä¹ˆå‘ç¥¨ï¼Ÿ",
            "expected_keywords": ["å‘ç¥¨", "æŠ¥é”€", "æµç¨‹"],
        },
        {
            "query": "é¤è¡¥æ ‡å‡†æ˜¯å¤šå°‘ï¼Ÿ",
            "expected_keywords": ["é¤è¡¥", "è¡¥è´´", "æ ‡å‡†"],
        },
        {
            "query": "æ€»ç›Ÿèƒ½ä½ä»€ä¹ˆé…’åº—ï¼Ÿ",
            "expected_keywords": ["æ€»ç›‘", "é…’åº—", "äº”æ˜Ÿçº§"],
        }
    ][:limit]
    
    print(f"\nğŸ§ª å¿«é€Ÿæµ‹è¯• ({len(test_queries)} æ¡):")
    
    results = []
    for i, test_case in enumerate(test_queries, 1):
        query = test_case["query"]
        keywords = test_case.get("expected_keywords", [])
        ground_truth = test_case.get("ground_truth", [])
        
        print(f"[{i}/{len(test_queries)}] {query}")
        
        try:
            start = time.time()
            response = rag_generator.generate(
                query=query,
                retrieval_config=RetrievalConfig(top_k=3),
                generation_config=GenerationConfig(
                    llm_provider=settings.llm_provider,
                    temperature=0.7,
                    max_tokens=300,
                ),
            )
            elapsed = (time.time() - start) * 1000
            
            answer = response.answer
            contexts = response.context_chunks or []
            
            # ç®€å•çš„å…³é”®è¯è¯„ä¼°
            answer_lower = answer.lower()
            hit_count = sum(1 for kw in keywords if kw.lower() in answer_lower)
            hit_rate = hit_count / len(keywords) if keywords else 1.0
            
            # æ¨¡æ‹ŸMRRè¯„ä¼°
            mrr_score = 1.0 if hit_rate > 0.5 else 0.0  # ç®€åŒ–ç‰ˆMRR
            
            status = "âœ…" if hit_rate >= 0.6 else "âš ï¸" if hit_rate >= 0.4 else "âŒ"
            
            print(f"   {status} {elapsed:.1f}ms | å…³é”®è¯:{hit_rate:.0%} | å›ç­”:{len(answer)}å­—ç¬¦")
            print(f"      å›ç­”: {answer[:60]}...")
            
            results.append({
                "query": query,
                "response_time_ms": elapsed,
                "hit_rate": hit_rate,
                "mrr": mrr_score,
                "answer_length": len(answer),
                "contexts_count": len(contexts),
            })
            
        except Exception as e:
            print(f"   âŒ å¤±è´¥: {str(e)[:50]}")
            results.append({
                "query": query,
                "error": str(e),
                "response_time_ms": 0,
                "hit_rate": 0,
                "mrr": 0,
                "answer_length": 0,
                "contexts_count": 0,
            })
    
    # ç»Ÿè®¡åˆ†æ
    valid_results = [r for r in results if "error" not in r]
    
    if valid_results:
        avg_time = statistics.mean([r["response_time_ms"] for r in valid_results])
        avg_hit_rate = statistics.mean([r["hit_rate"] for r in valid_results])
        avg_mrr = statistics.mean([r["mrr"] for r in valid_results])
        avg_length = statistics.mean([r["answer_length"] for r in valid_results])
        
        print("\nğŸ“Š å¿«é€Ÿæµ‹è¯„ç»“æœ:")
        print(f"   æµ‹è¯•æ•°é‡: {len(valid_results) / {len(test_queries)}")
        print(f"   å¹³å‡å“åº”æ—¶é—´: {avg_time:.1f}ms")
        print(f"   å¹³å‡å…³é”®è¯å‘½ä¸­ç‡: {avg_hit_rate:.1%}")
        print(f"   å¹³å‡MRR: {avg_mrr:.3f}")
        print(f"   å¹³å‡å›ç­”é•¿åº¦: {avg_length:.0f}å­—ç¬¦")
        
        if avg_hit_rate >= 0.8:
            print("   ğŸŸ¢ ä¼˜ç§€ - æœ¬åœ°RAGç³»ç»Ÿè¡¨ç°è‰¯å¥½")
        elif avg_hit_rate >= 0.6:
            print("   ğŸŸ¡ è‰¯å¥½ - æœ¬åœ°RAGç³»ç»Ÿå¯ç”¨")
        else:
            print("   ğŸŸ  éœ€ä¼˜åŒ– - æœ¬åœ°RAGç³»ç»Ÿéœ€è¦è°ƒæ•´")
    else:
        print("   âŒ æµ‹è¯•å¤±è´¥")
        
        print("="*60)
        print("ğŸ’¡ å®Œæ•´æµ‹è¯„:")
        print("   python local_eval.py --limit 10")
        print("   å¿«é€ŸéªŒè¯: python quick_eval.py")
        print("   MRRä¿®å¤: python mrr_debug.py")
        
        return {
            "quick_results": results,
            "statistics": {
                "avg_response_time_ms": avg_time,
                "avg_hit_rate": avg_hit_rate,
                "avg_mrr": avg_mrr,
                "avg_answer_length": avg_length,
                "success_rate": len(valid_results) / len(test_cases) if 'test_cases' in locals() else len(valid_results) / len(test_queries)
            }
        }


def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description="RAGç³»ç»Ÿå¿«é€Ÿæµ‹è¯„ï¼ˆæœ¬åœ°æ¨¡å‹ï¼‰")
    parser.add_argument("--limit", type=int, default=5, help="é™åˆ¶æµ‹è¯•æ•°é‡")
    
    args = parser.parse_args()
    
    quick_local_eval(args.limit)


if __name__ == "__main__":
    main()
