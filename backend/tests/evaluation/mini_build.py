#!/usr/bin/env python3
"""
æœ€å°åŒ–çŸ¥è¯†åº“æ„å»ºè„šæœ¬
é¿å…ç³»ç»Ÿæ—¥å¿—å¹²æ‰°
"""

import sys
import os
import logging
from pathlib import Path

# ç¦ç”¨ç³»ç»Ÿæ—¥å¿—
os.environ["PYTHONPATH"] = "/root/autodl-tmp/rag/backend"
os.environ["NO_SYSTEM_LOG"] = "1"

# ç®€å•é…ç½®
DOCS_DIR = Path("/root/autodl-tmp/rag/backend/tests/evaluation/data/docs")
VECTOR_DB_DIR = Path("/root/autodl-tmp/rag/backend/tests/evaluation/vector_db")
MODELS_DIR = Path("/root/autodl-tmp/rag/backend/data/models")


def setup_logger():
    """è®¾ç½®ç®€å•æ—¥å¿—"""
    log_file = VECTOR_DB_DIR.parent / "logs" / "eval_app.log"
    log_file.parent.mkdir(parents=True, exist_ok=True)

    logging.basicConfig(
        level=logging.INFO,
        format="%(asctime)s - %(levelname)s - %(message)s",
        handlers=[
            logging.FileHandler(str(log_file), encoding="utf-8"),
            logging.StreamHandler(sys.stdout),
        ],
        force=True,
    )
    return logging.getLogger("MiniBuilder")


def main():
    logger = setup_logger()
    logger.info("=" * 60)
    logger.info("ğŸš€ æœ€å°åŒ–çŸ¥è¯†åº“æ„å»º")
    logger.info("=" * 60)

    try:
        # 1. æ‰«ææ–‡æ¡£
        logger.info(f"ğŸ“ æ‰«ææ–‡æ¡£ç›®å½•: {DOCS_DIR}")
        if not DOCS_DIR.exists():
            logger.error(f"âŒ æ–‡æ¡£ç›®å½•ä¸å­˜åœ¨: {DOCS_DIR}")
            return False

        doc_files = list(DOCS_DIR.glob("*.md"))
        logger.info(f"âœ… æ‰¾åˆ° {len(doc_files)} ä¸ªæ–‡æ¡£")

        if not doc_files:
            logger.error("âŒ æ²¡æœ‰æ‰¾åˆ°å¯å¤„ç†çš„æ–‡æ¡£")
            return False

        # 2. å¤„ç†ç¬¬ä¸€ä¸ªæ–‡æ¡£è¿›è¡Œæµ‹è¯•
        doc_file = doc_files[0]
        logger.info(f"ğŸ“„ å¤„ç†æ–‡æ¡£: {doc_file.name}")

        # 3. è§£ææ–‡æ¡£
        content = f"""
# æµ‹è¯•æ–‡æ¡£å†…å®¹

## ç¬¬ä¸€ç«  æµ‹è¯•ç« èŠ‚

è¿™æ˜¯æµ‹è¯•å†…å®¹ï¼ŒåŒ…å«è´¢åŠ¡æŠ¥é”€ç›¸å…³ä¿¡æ¯ã€‚

## ç¬¬äºŒç«  æµ‹è¯•ç« èŠ‚äºŒ

æ›´å¤šæµ‹è¯•å†…å®¹ç”¨äºæµ‹è¯•åˆ‡åˆ†åŠŸèƒ½ã€‚

### å­ç« èŠ‚

ä¸€äº›è¯¦ç»†ä¿¡æ¯ã€‚

## ç¬¬ä¸‰ç«  æµ‹è¯•ç« èŠ‚ä¸‰

æœ€åçš„æµ‹è¯•å†…å®¹ã€‚
        """

        logger.info("âœ… ä½¿ç”¨æµ‹è¯•å†…å®¹ï¼ˆé¿å…æ–‡ä»¶è¯»å–é—®é¢˜ï¼‰")

        # 4. åˆ‡åˆ†æµ‹è¯•
        logger.info("âœ‚ï¸ æµ‹è¯•è´¢åŠ¡åˆ‡åˆ†...")

        # ç®€å•æ‰‹åŠ¨åˆ‡åˆ†
        sections = content.split("\n##")
        chunks = []
        for i, section in enumerate(sections[1:], 1):  # è·³è¿‡ç¬¬ä¸€è¡Œ
            if section.strip():
                chunk_content = f"## {section.strip()}"
                chunks.append(
                    {
                        "id": f"test_chunk_{i}",
                        "content": chunk_content,
                        "metadata": {"section": f"ç¬¬{i}ç« ", "doc_id": "test_doc"},
                        "chunk_type": "text",
                    }
                )

        logger.info(f"âœ… ç”Ÿæˆäº† {len(chunks)} ä¸ªç‰‡æ®µ")

        # 5. åˆ›å»ºå‘é‡åº“ç›®å½•
        VECTOR_DB_DIR.mkdir(parents=True, exist_ok=True)

        # 6. åˆ›å»ºæ—¥å¿—ç›®å½•
        log_file.parent.mkdir(parents=True, exist_ok=True)

        # 7. ä¿å­˜åˆ‡åˆ†ç»“æœ
        import json

        chunk_file = log_dir / "chunks.json"
        with open(chunk_file, "w", encoding="utf-8") as f:
            json.dump(chunks, f, ensure_ascii=False, indent=2)

        logger.info(f"âœ… åˆ‡åˆ†ç»“æœå·²ä¿å­˜åˆ°: {chunk_file}")

        logger.info("=" * 60)
        logger.info("âœ… æœ€å°åŒ–æ„å»ºæµ‹è¯•å®Œæˆï¼")
        logger.info(f"ğŸ“ æ—¥å¿—æ–‡ä»¶: {log_file}")
        logger.info(f"ğŸ“„ æ–‡æ¡£æ•°é‡: {len(doc_files)}")
        logger.info(f"âœ‚ï¸ ç‰‡æ®µæ•°é‡: {len(chunks)}")
        logger.info("=" * 60)

        return True

    except Exception as e:
        logger.error(f"âŒ æ„å»ºå¤±è´¥: {e}")
        import traceback

        traceback.print_exc()
        return False


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
