"""
æ·±åº¦è¯Šæ–­æ£€ç´¢é—®é¢˜
"""

import requests
import json
import numpy as np


def debug_retrieval():
    """æ·±åº¦è°ƒè¯•æ£€ç´¢è¿‡ç¨‹"""
    print("=" * 70)
    print("ğŸ” æ·±åº¦è¯Šæ–­æ£€ç´¢é—®é¢˜")
    print("=" * 70)

    # 1. æµ‹è¯•ç®€å•çš„å…³é”®è¯æ£€ç´¢
    test_queries = [
        "é€šè®¯è´¹",
        "æŠ¥é”€",
        "é€šè®¯è´¹æŠ¥é”€",
        "ä¸»ç®¡ æŠ¥é”€ æ ‡å‡†",
        "150å…ƒ",
        "æ‰‹æœºè´¹",
        "é€šä¿¡è¡¥è´´",
    ]

    print("\nğŸ“Š æµ‹è¯•ä¸åŒæŸ¥è¯¢è¯:")
    for query in test_queries:
        resp = requests.post(
            "http://localhost:8000/retrieval/search",
            json={
                "query": query,
                "config": {
                    "top_k": 5,
                    "similarity_threshold": 0.0,  # ä¸è®¾é˜ˆå€¼ï¼Œçœ‹æ‰€æœ‰ç»“æœ
                    "algorithm": "cosine",
                },
            },
        )
        result = resp.json()
        print(f"   '{query}': {result['total']} æ¡ç»“æœ")
        if result["results"]:
            for r in result["results"][:2]:
                print(f"      â†’ {r['document_name']}: {r['similarity']:.3f}")

    # 2. æ£€æŸ¥baoxiao.mdçš„å†…å®¹
    print("\nğŸ“„ æ£€æŸ¥baoxiao.mdçš„å®é™…å†…å®¹:")
    try:
        with open("/root/autodl-tmp/rag/backend/data/docs/baoxiao.md", "r") as f:
            content = f.read()
            # æŸ¥æ‰¾é€šè®¯è´¹ç›¸å…³å†…å®¹
            import re

            matches = re.findall(
                r"[#\*\-].*?(?:é€šè®¯|é€šä¿¡|æ‰‹æœº|ç”µè¯).*?(?:è´¹|è¡¥è´´|æŠ¥é”€).*",
                content,
                re.IGNORECASE,
            )
            print(f"   æ‰¾åˆ° {len(matches)} å¤„é€šè®¯è´¹ç›¸å…³å†…å®¹:")
            for i, m in enumerate(matches[:5], 1):
                print(f"      {i}. {m[:80]}...")
    except Exception as e:
        print(f"   âŒ è¯»å–å¤±è´¥: {e}")

    # 3. ç›´æ¥æµ‹è¯•å‘é‡æœç´¢
    print("\nğŸ” æµ‹è¯•åº•å±‚å‘é‡æœç´¢:")
    from services.vector_db import vector_db_manager
    from services.embedding import embedding_service

    if embedding_service.is_loaded() and vector_db_manager.db:
        query = "é€šè®¯è´¹æŠ¥é”€æ ‡å‡†"
        query_vector = embedding_service.encode([query])[0]

        print(f"   æŸ¥è¯¢å‘é‡ç»´åº¦: {len(query_vector)}")
        print(f"   æŸ¥è¯¢å‘é‡å‰5ä¸ªå€¼: {query_vector[:5]}")
        print(f"   æŸ¥è¯¢å‘é‡èŒƒæ•°: {np.linalg.norm(query_vector):.4f}")

        # æ‰§è¡Œæœç´¢
        distances, metadata_list = vector_db_manager.search(query_vector, top_k=5)
        print(f"\n   FAISSè¿”å›ç»“æœ:")
        print(f"   - è·ç¦»å€¼: {distances[0][:5] if len(distances) > 0 else 'N/A'}")
        print(f"   - ç»“æœæ•°: {len(distances[0]) if len(distances) > 0 else 0}")

        if len(distances) > 0 and len(distances[0]) > 0:
            print(f"\n   åŸå§‹è·ç¦»å€¼åˆ†æ:")
            for i, (dist, meta) in enumerate(
                zip(distances[0][:3], metadata_list[0][:3])
            ):
                print(f"      ç»“æœ{i + 1}: è·ç¦»={dist:.4f}")
                # è®¡ç®—ç†è®ºç›¸ä¼¼åº¦
                cosine_sim = 1 - (dist**2) / 2
                print(f"              ä½™å¼¦ç›¸ä¼¼åº¦={max(0, min(1, cosine_sim)):.4f}")
                if isinstance(meta, dict):
                    print(
                        f"              æ–‡æ¡£: {meta.get('document_name', 'N/A')[:30]}"
                    )
    else:
        print("   âš ï¸ æœåŠ¡æœªåŠ è½½ï¼Œè·³è¿‡å‘é‡æµ‹è¯•")

    print("\n" + "=" * 70)
    print("ğŸ’¡ è¯Šæ–­ç»“è®º:")
    print("=" * 70)


if __name__ == "__main__":
    debug_retrieval()
