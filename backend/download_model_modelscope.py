#!/usr/bin/env python3
"""
ä» ModelScope ä¸‹è½½ Qwen2.5-0.5B-Instruct æ¨¡å‹
"""

from modelscope import snapshot_download
import os
from pathlib import Path

def download_qwen_model():
    """ä» ModelScope ä¸‹è½½ Qwen2.5-0.5B-Instruct æ¨¡å‹"""

    print("=" * 70)
    print("ä» ModelScope ä¸‹è½½ Qwen2.5-0.5B-Instruct æ¨¡å‹")
    print("=" * 70)
    print()

    # æ¨¡å‹ç›®å½•
    model_dir = Path("/root/autodl-tmp/rag/backend/data/models/Qwen2.5-0.5B-Instruct")
    model_dir.mkdir(parents=True, exist_ok=True)

    print(f"æ¨¡å‹å°†ä¸‹è½½åˆ°: {model_dir.absolute()}")
    print()
    print("æ¨¡å‹ä¿¡æ¯:")
    print("  - æ¨¡å‹åç§°: Qwen/Qwen2.5-0.5B-Instruct")
    print("  - æ¨¡å‹å¤§å°: çº¦ 1GB")
    print("  - é€‚ç”¨åœºæ™¯: ä¸­æ–‡å¯¹è¯ã€RAGã€é—®ç­”")
    print()

    try:
        print("å¼€å§‹ä¸‹è½½...")
        print("-" * 70)

        model_dir = snapshot_download(
            'Qwen/Qwen2.5-0.5B-Instruct',
            cache_dir='/root/autodl-tmp/rag/backend/data/models',
            revision='master'
        )

        print("-" * 70)
        print()
        print("=" * 70)
        print("âœ… æ¨¡å‹ä¸‹è½½å®Œæˆ!")
        print("=" * 70)
        print()
        print(f"æ¨¡å‹è·¯å¾„: {model_dir}")
        print()

        # æ£€æŸ¥ä¸‹è½½çš„æ–‡ä»¶
        print("ä¸‹è½½çš„æ–‡ä»¶:")
        print("-" * 70)
        for item in sorted(model_dir.iterdir()):
            if item.is_file():
                size_mb = item.stat().st_size / (1024 * 1024)
                print(f"  {item.name:40s} {size_mb:>8.2f} MB")
            elif item.is_dir():
                print(f"  {item.name}/ (ç›®å½•)")
        print()

        print("=" * 70)
        print("ä¸‹ä¸€æ­¥é…ç½®:")
        print("=" * 70)
        print()
        print("åœ¨ .env æ–‡ä»¶ä¸­æ·»åŠ :")
        print("  LLM_PROVIDER=local")
        print("  LLM_MODEL=Qwen2.5-0.5B-Instruct")
        print(f"  LOCAL_LLM_MODEL_PATH={model_dir}")
        print("  LOCAL_LLM_DEVICE=cpu")
        print()
        print("æˆ–ç›´æ¥ä¿®æ”¹ config.py:")
        print("  llm_provider: str = \"local\"")
        print(f"  local_llm_model_path: str = \"{model_dir}\"")
        print("  local_llm_device: str = \"cpu\"")
        print()
        print("ç„¶åé‡å¯åç«¯æœåŠ¡:")
        print("  python main.py")
        print()

        return True

    except Exception as e:
        print()
        print("=" * 70)
        print("âŒ ä¸‹è½½å¤±è´¥!")
        print("=" * 70)
        print(f"é”™è¯¯ä¿¡æ¯: {str(e)}")
        print()
        print("å¯èƒ½çš„åŸå› :")
        print("  1. ç½‘ç»œè¿æ¥é—®é¢˜")
        print("  2. ModelScope æœåŠ¡æš‚æ—¶ä¸å¯ç”¨")
        print("  3. ç£ç›˜ç©ºé—´ä¸è¶³")
        print()
        print("å»ºè®®:")
        print("  1. æ£€æŸ¥ç½‘ç»œè¿æ¥")
        print("  2. æ£€æŸ¥ç£ç›˜ç©ºé—´: df -h")
        print("  3. ç¨åé‡è¯•")
        print()
        import traceback
        traceback.print_exc()
        return False


if __name__ == "__main__":
    success = download_qwen_model()

    if success:
        print("ğŸ‰ é…ç½®å®Œæˆï¼ç°åœ¨å¯ä»¥å¼€å§‹ä½¿ç”¨æœ¬åœ° LLM äº†ã€‚")
    else:
        print("âŒ ä¸‹è½½å¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯åé‡è¯•ã€‚")