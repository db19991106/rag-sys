#!/usr/bin/env python3
"""
å¿«é€ŸRAGéªŒè¯è„šæœ¬ - æ— éœ€RAGASï¼Œå¿«é€ŸéªŒè¯ç³»ç»ŸåŠŸèƒ½
"""

import sys
import time
from pathlib import Path
from datetime import datetime

sys.path.insert(0, str(Path(__file__).parent))

from services.rag_generator import rag_generator
from services.embedding import embedding_service
from services.vector_db import vector_db_manager
from models import RetrievalConfig, GenerationConfig, EmbeddingConfig, VectorDBConfig
from models import EmbeddingModelType, VectorDBType


def quick_test():
    """å¿«é€Ÿæµ‹è¯•RAGç³»ç»Ÿ"""

    print("=" * 70)
    print("ğŸš€ RAGç³»ç»Ÿå¿«é€ŸéªŒè¯")
    print("=" * 70)
    print()

    # åˆå§‹åŒ–æœåŠ¡
    print("ğŸ“¦ åˆå§‹åŒ–æœåŠ¡...")
    if not embedding_service.is_loaded():
        config = EmbeddingConfig(
            model_type=EmbeddingModelType.BGE,
            model_name="BAAI/bge-small-zh-v1.5",
            device="cpu",
        )
        embedding_service.load_model(config)

    dimension = embedding_service.get_dimension()
    vdb_config = VectorDBConfig(
        db_type=VectorDBType.FAISS, dimension=dimension, index_type="HNSW"
    )
    vector_db_manager.initialize(vdb_config)

    status = vector_db_manager.get_status()
    print(f"   âœ… å‘é‡åº“: {status.total_vectors} ä¸ªå‘é‡\n")

    # æµ‹è¯•ç”¨ä¾‹
    test_cases = [
        {
            "query": "8-9çº§å‘˜å·¥ä½å®¿æ ‡å‡†",
            "expected_keywords": ["ä½å®¿", "ä¸‰æ˜Ÿçº§", "300", "æ™®é€šå‘˜å·¥"],
        },
        {
            "query": "ç»ç†åé«˜é“å¯ä»¥é€‰ä»€ä¹ˆåº§ä½",
            "expected_keywords": ["ç»ç†", "é«˜é“", "ä¸€ç­‰åº§"],
        },
        {
            "query": "æŠ¥é”€æµç¨‹æ˜¯ä»€ä¹ˆ",
            "expected_keywords": ["æŠ¥é”€", "æµç¨‹", "å®¡æ‰¹", "å‘ç¥¨"],
        },
    ]

    results = []

    for i, case in enumerate(test_cases, 1):
        print(f"[{i}/{len(test_cases)}] {case['query']}")

        # è¿è¡ŒRAG - ä½¿ç”¨æœ¬åœ°æ¨¡å‹é…ç½®
        from config import settings

        start = time.time()
        response = rag_generator.generate(
            query=case["query"],
            retrieval_config=RetrievalConfig(top_k=3),
            generation_config=GenerationConfig(
                llm_provider=settings.llm_provider,
                llm_model=settings.llm_model,
                temperature=0.7,
                max_tokens=300,
            ),
        )
        elapsed = time.time() - start

        # æ£€æŸ¥ç»“æœ
        answer = response.answer
        contexts = response.context_chunks

        # å…³é”®è¯åŒ¹é…
        matched_keywords = [
            kw for kw in case["expected_keywords"] if kw.lower() in answer.lower()
        ]
        keyword_match_rate = len(matched_keywords) / len(case["expected_keywords"])

        # è¯„åˆ†
        if keyword_match_rate >= 0.7:
            score = "ğŸŸ¢ ä¼˜ç§€"
        elif keyword_match_rate >= 0.4:
            score = "ğŸŸ¡ è‰¯å¥½"
        else:
            score = "ğŸ”´ éœ€ä¼˜åŒ–"

        print(f"   æ£€ç´¢: {len(contexts)} ä¸ªç‰‡æ®µ")
        print(f"   å›ç­”: {len(answer)} å­—ç¬¦")
        print(
            f"   å…³é”®è¯åŒ¹é…: {len(matched_keywords)}/{len(case['expected_keywords'])} {score}"
        )
        print(f"   è€—æ—¶: {elapsed:.1f}s")
        print(f"   å›ç­”é¢„è§ˆ: {answer[:100]}...")
        print()

        results.append(
            {
                "query": case["query"],
                "retrieved": len(contexts),
                "answer_length": len(answer),
                "keyword_match": keyword_match_rate,
                "time": elapsed,
            }
        )

    # æ€»ç»“
    print("=" * 70)
    print("ğŸ“Š éªŒè¯æ€»ç»“")
    print("=" * 70)

    avg_time = sum(r["time"] for r in results) / len(results)
    avg_match = sum(r["keyword_match"] for r in results) / len(results)

    print(f"âœ… æµ‹è¯•é€šè¿‡: {len(results)}/{len(results)}")
    print(f"â±ï¸  å¹³å‡å“åº”æ—¶é—´: {avg_time:.1f}s")
    print(f"ğŸ¯ å¹³å‡å…³é”®è¯åŒ¹é…ç‡: {avg_match * 100:.0f}%")

    if avg_match >= 0.7:
        print("ğŸ‰ ç³»ç»ŸçŠ¶æ€: ä¼˜ç§€")
    elif avg_match >= 0.4:
        print("ğŸ‘ ç³»ç»ŸçŠ¶æ€: è‰¯å¥½")
    else:
        print("âš ï¸  ç³»ç»ŸçŠ¶æ€: éœ€ä¼˜åŒ–")

    print("=" * 70)
    print("\næç¤º: å¦‚éœ€è¯¦ç»†RAGASè¯„ä¼°æŒ‡æ ‡ï¼Œå»ºè®®:")
    print("  1. é…ç½®OpenAI API Keyè¿›è¡Œäº‘ç«¯è¯„ä¼°")
    print("  2. æˆ–ä½¿ç”¨æ›´å¤§å‚æ•°é‡çš„æœ¬åœ°æ¨¡å‹ï¼ˆå¦‚qwen2.5:7bï¼‰")
    print("  3. äººå·¥æŠ½æŸ¥å›ç­”è´¨é‡")


if __name__ == "__main__":
    quick_test()
