#!/usr/bin/env python3
"""
å¿«é€Ÿè®¾ç½®æœ¬åœ°æ¨¡å‹è¯„ä¼°ç¯å¢ƒ
ä¸€é”®é…ç½®è„šæœ¬
"""

import subprocess
import sys
from pathlib import Path


def run_command(cmd, description):
    """è¿è¡Œå‘½ä»¤å¹¶æ˜¾ç¤ºç»“æœ"""
    print(f"\n{'=' * 60}")
    print(f"{description}")
    print(f"{'=' * 60}")
    print(f"å‘½ä»¤: {cmd}\n")

    result = subprocess.run(cmd, shell=True, capture_output=False, text=True)
    return result.returncode == 0


def main():
    print("â•”" + "â•" * 58 + "â•—")
    print("â•‘" + " " * 15 + "RAGæœ¬åœ°æ¨¡å‹å¿«é€Ÿè®¾ç½®å·¥å…·" + " " * 20 + "â•‘")
    print("â•š" + "â•" * 58 + "â•")
    print()

    # æ­¥éª¤1: å®‰è£…ä¾èµ–
    print("ğŸ“¦ æ­¥éª¤1: å®‰è£…å¿…è¦ä¾èµ–")
    print("-" * 60)

    deps = ["ragas", "langchain-community", "huggingface_hub", "modelscope"]

    for dep in deps:
        print(f"\nå®‰è£… {dep}...")
        subprocess.run(
            [sys.executable, "-m", "pip", "install", dep], capture_output=True
        )

    print("\nâœ… ä¾èµ–å®‰è£…å®Œæˆ")

    # æ­¥éª¤2: é€‰æ‹©æ¨¡å‹æ¥æº
    print("\n" + "=" * 60)
    print("ğŸ¤– æ­¥éª¤2: é€‰æ‹©æœ¬åœ°æ¨¡å‹æ–¹æ¡ˆ")
    print("=" * 60)
    print()
    print("æ–¹æ¡ˆA: ä½¿ç”¨Ollamaï¼ˆæœ€ç®€å•ï¼Œæ¨èï¼‰")
    print("  - æ— éœ€é…ç½®ï¼Œç›´æ¥è¿è¡Œ")
    print("  - è‡ªåŠ¨ç®¡ç†æ¨¡å‹")
    print("  - é€‚åˆå¿«é€Ÿæµ‹è¯•")
    print()
    print("æ–¹æ¡ˆB: ä»ModelScopeä¸‹è½½ï¼ˆä¸­æ–‡ä¼˜åŒ–ï¼‰")
    print("  - ä¸‹è½½åˆ°æœ¬åœ°ç›®å½•")
    print("  - å®Œå…¨ç¦»çº¿è¿è¡Œ")
    print("  - éœ€è¦è¾ƒé•¿æ—¶é—´ä¸‹è½½")
    print()

    choice = input("è¯·é€‰æ‹© (A/B): ").strip().upper()

    if choice == "A":
        # Ollamaæ–¹æ¡ˆ
        print("\n" + "=" * 60)
        print("ğŸ³ Ollamaæ–¹æ¡ˆ")
        print("=" * 60)

        # æ£€æŸ¥Ollamaæ˜¯å¦å·²å®‰è£…
        result = subprocess.run(["which", "ollama"], capture_output=True)
        if result.returncode != 0:
            print("âš ï¸  Ollamaæœªå®‰è£…")
            print()
            print("å®‰è£…æ–¹æ³•:")
            print("  Linux/macOS: curl -fsSL https://ollama.com/install.sh | sh")
            print("  Docker: docker run -d -p 11434:11434 ollama/ollama")
            print()
            input("å®‰è£…å®ŒæˆåæŒ‰å›è½¦ç»§ç»­...")

        # æ‹‰å–æ¨¡å‹
        print("\nğŸ“¥ æ‹‰å–Qwen2.5æ¨¡å‹...")
        print("è¿è¡Œ: ollama pull qwen2.5:0.5b")

        result = subprocess.run(["ollama", "pull", "qwen2.5:0.5b"])
        if result.returncode != 0:
            print("âŒ æ¨¡å‹æ‹‰å–å¤±è´¥")
            return

        print("âœ… æ¨¡å‹æ‹‰å–å®Œæˆ")

        # æµ‹è¯•è¿æ¥
        print("\nğŸ§ª æµ‹è¯•æ¨¡å‹è¿æ¥...")
        result = subprocess.run(
            ["ollama", "run", "qwen2.5:0.5b", "ä½ å¥½"],
            capture_output=True,
            text=True,
            timeout=30,
        )

        if result.returncode == 0:
            print("âœ… æ¨¡å‹è¿æ¥æ­£å¸¸")
        else:
            print("âš ï¸  æ¨¡å‹æµ‹è¯•æœªå®Œæˆï¼Œä½†æ¨¡å‹å·²ä¸‹è½½")

        # é…ç½®å®Œæˆæç¤º
        print("\n" + "=" * 60)
        print("âœ… è®¾ç½®å®Œæˆï¼")
        print("=" * 60)
        print()
        print("è¿è¡Œè¯„ä¼°å‘½ä»¤:")
        print()
        print("  cd /root/autodl-tmp/rag/backend")
        print("  python local_ragas_integration.py \\")
        print("    --provider ollama \\")
        print("    --model qwen2.5:0.5b \\")
        print("    --mode batch")
        print()

    elif choice == "B":
        # ModelScopeæ–¹æ¡ˆ
        print("\n" + "=" * 60)
        print("ğŸ“¥ ModelScopeæ–¹æ¡ˆ")
        print("=" * 60)

        print("\nå¼€å§‹ä¸‹è½½æ¨¡å‹ï¼ˆçº¦1GBï¼Œå¯èƒ½éœ€è¦5-10åˆ†é’Ÿï¼‰...")
        print()

        result = subprocess.run([sys.executable, "download_model.py"])

        if result.returncode != 0:
            print("âŒ æ¨¡å‹ä¸‹è½½å¤±è´¥")
            return

        print("\n" + "=" * 60)
        print("âœ… è®¾ç½®å®Œæˆï¼")
        print("=" * 60)
        print()
        print("è¿è¡Œè¯„ä¼°å‘½ä»¤:")
        print()
        print("  cd /root/autodl-tmp/rag/backend")
        print("  python project_local_ragas.py --mode batch")
        print()

    else:
        print("âŒ æ— æ•ˆé€‰æ‹©")
        return

    print("æç¤º:")
    print("  - è¯„ä¼°ç»“æœå°†ä¿å­˜åœ¨ evaluation_results/ ç›®å½•")
    print("  - é¦–æ¬¡è¿è¡Œå¯èƒ½éœ€è¦å‡ åˆ†é’ŸåŠ è½½æ¨¡å‹")
    print("  - å¦‚éœ€å¸®åŠ©ï¼ŒæŸ¥çœ‹ LOCAL_LLM_EVALUATION_GUIDE.md")
    print()


if __name__ == "__main__":
    main()
