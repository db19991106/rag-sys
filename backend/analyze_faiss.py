#!/usr/bin/env python3
"""
æ·±åº¦åˆ†æFAISSç´¢å¼•é—®é¢˜
"""

import sys

sys.path.insert(0, "/root/autodl-tmp/rag/backend")

import faiss
import numpy as np
from services.vector_db import vector_db_manager
from services.embedding import embedding_service

print("=" * 70)
print("ğŸ”¬ FAISSç´¢å¼•æ·±åº¦åˆ†æ")
print("=" * 70)

# 1. æ£€æŸ¥FAISSç´¢å¼•ç±»å‹
print("\n1. FAISSç´¢å¼•ä¿¡æ¯:")
if vector_db_manager.db and vector_db_manager.db.index:
    index = vector_db_manager.db.index
    print(f"   ç´¢å¼•ç±»å‹: {type(index).__name__}")
    print(f"   æ˜¯å¦è®­ç»ƒ: {index.is_trained}")
    print(f"   ç»´åº¦: {index.d}")
    print(f"   å‘é‡æ•°: {index.ntotal}")

    # æ£€æŸ¥HNSWå‚æ•°
    if hasattr(index, "hnsw"):
        print(f"   HNSWå‚æ•°:")
        print(f"     - M: {index.hnsw.M}")
        print(f"     - efConstruction: {index.hnsw.efConstruction}")
        print(f"     - efSearch: {index.hnsw.efSearch}")
else:
    print("   âŒ ç´¢å¼•æœªåˆå§‹åŒ–")
    sys.exit(1)

# 2. è·å–æ•°æ®åº“ä¸­çš„ä¸€ä¸ªå‘é‡æ ·æœ¬
print("\n2. å‘é‡æ ·æœ¬åˆ†æ:")
if vector_db_manager.db.metadata:
    sample_key = list(vector_db_manager.db.metadata.keys())[0]
    sample_meta = vector_db_manager.db.metadata[sample_key]
    print(f"   æ ·æœ¬Key: {sample_key}")
    print(
        f"   æ ·æœ¬æ–‡æ¡£: {sample_meta.get('document_name', 'Unknown') if isinstance(sample_meta, dict) else 'N/A'}"
    )

    # ä»FAISSä¸­é‡å»ºå‘é‡
    try:
        sample_vector = index.reconstruct(int(sample_key))
        print(f"   å‘é‡ç»´åº¦: {len(sample_vector)}")
        print(f"   å‘é‡èŒƒæ•°: {np.linalg.norm(sample_vector):.6f}")
        print(f"   å‘é‡å‰5ä¸ªå€¼: {sample_vector[:5]}")

        # æ£€æŸ¥æ˜¯å¦å½’ä¸€åŒ–
        norm = np.linalg.norm(sample_vector)
        is_normalized = abs(norm - 1.0) < 0.01
        print(f"   æ˜¯å¦å½’ä¸€åŒ–: {is_normalized} (èŒƒæ•°={norm:.6f})")
    except Exception as e:
        print(f"   âŒ é‡å»ºå‘é‡å¤±è´¥: {e}")

# 3. æµ‹è¯•æŸ¥è¯¢å‘é‡
print("\n3. æŸ¥è¯¢å‘é‡åˆ†æ:")
query = "é€šè®¯è´¹æŠ¥é”€"
query_vector = embedding_service.encode([query])[0]
print(f"   æŸ¥è¯¢: '{query}'")
print(f"   å‘é‡ç»´åº¦: {len(query_vector)}")
print(f"   å‘é‡èŒƒæ•°: {np.linalg.norm(query_vector):.6f}")
print(f"   å‘é‡å‰5ä¸ªå€¼: {query_vector[:5]}")

norm = np.linalg.norm(query_vector)
is_normalized = abs(norm - 1.0) < 0.01
print(f"   æ˜¯å¦å½’ä¸€åŒ–: {is_normalized} (èŒƒæ•°={norm:.6f})")

# 4. æ‰§è¡Œæœç´¢å¹¶åˆ†æè·ç¦»
print("\n4. æœç´¢ç»“æœåˆ†æ:")
if query_vector.ndim == 1:
    query_vector = query_vector.reshape(1, -1)

distances, indices = index.search(query_vector.astype("float32"), k=5)
print(f"   è¿”å›è·ç¦»: {distances[0]}")
print(f"   è¿”å›ç´¢å¼•: {indices[0]}")

# 5. è®¡ç®—ç›¸ä¼¼åº¦
print("\n5. ç›¸ä¼¼åº¦è®¡ç®—:")
for i, (dist, idx) in enumerate(zip(distances[0], indices[0])):
    if idx >= 0:
        # å‡è®¾æ˜¯å½’ä¸€åŒ–å‘é‡ï¼Œä½¿ç”¨ä½™å¼¦ç›¸ä¼¼åº¦å…¬å¼
        cosine_sim = 1 - (dist**2) / 2
        cosine_sim = max(0.0, min(1.0, cosine_sim))
        print(
            f"   ç»“æœ{i + 1}: ç´¢å¼•={idx}, è·ç¦»={dist:.6f}, ä½™å¼¦ç›¸ä¼¼åº¦={cosine_sim:.6f}"
        )

        # æ£€æŸ¥åŸå§‹å‘é‡
        try:
            doc_vector = index.reconstruct(int(idx))
            doc_norm = np.linalg.norm(doc_vector)
            query_norm = np.linalg.norm(query_vector[0])
            actual_cosine = np.dot(doc_vector, query_vector[0]) / (
                doc_norm * query_norm
            )
            print(f"            å®é™…ä½™å¼¦ç›¸ä¼¼åº¦: {actual_cosine:.6f}")
            print(f"            æ–‡æ¡£èŒƒæ•°: {doc_norm:.6f}")
        except Exception as e:
            print(f"            æ— æ³•é‡å»º: {e}")

# 6. æ£€æŸ¥å…ƒæ•°æ®
print("\n6. æ£€æŸ¥å…ƒæ•°æ®å¯¹åº”:")
for idx in indices[0][:3]:
    if idx >= 0:
        meta = vector_db_manager.db.metadata.get(str(idx), {})
        if isinstance(meta, dict):
            print(f"   ç´¢å¼•{idx}: {meta.get('document_name', 'Unknown')[:40]}")
        else:
            print(f"   ç´¢å¼•{idx}: å…ƒæ•°æ®æ ¼å¼é”™è¯¯ - {type(meta)}")

print("\n" + "=" * 70)
print("ğŸ’¡ è¯Šæ–­ç»“è®º:")
print("=" * 70)
